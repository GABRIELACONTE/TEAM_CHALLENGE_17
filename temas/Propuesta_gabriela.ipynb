{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d268a0f7-7018-43db-bee0-72a54f6fa19f",
   "metadata": {},
   "source": [
    "DATASET: https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023\n",
    "\n",
    "### Planteamiento del problema de negocio\n",
    "\n",
    "En este estudio, nuestro objetivo es predecir el salario de profesionales en ciencia de datos en función de diversas variables relacionadas con el trabajo, la experiencia y la ubicación.\n",
    "\n",
    "Hemos elegido el conjunto de datos \"Salarios de ciencia de datos 2023\" porque:\n",
    "Contiene información relevante como título del trabajo, nivel de experiencia, tipo de empleo, ubicación de la empresa y salario .\n",
    "Incluye variables numéricas y categóricas , lo que permite aplicar técnicas de preprocesamiento como PCA (no supervisado) y modelos de regresión (supervisado) .\n",
    "\n",
    "El salario es una variable continua , lo que nos lleva a un problema de regresión en lugar de clasificación.\n",
    "Es útil en la vida real: entender qué factores influyen en el salario puede ayudar tanto a compañeros como a profesionales de datos.\n",
    " \n",
    "Estructura del análisis\n",
    "Vamos a dividir el análisis en varias fases:\n",
    "\n",
    "* 1️ Exploración y análisis inicial de los datos.\n",
    "\n",
    "\n",
    "Antes de aplicar cualquier modelo, debemos entender cómo están estructurados los datos:\n",
    "\n",
    "• Distribución de la variable objetivo (salario) → Ver si es normal, sesgada, etc\n",
    "\n",
    "• Correlación entre variables numéricas → Identificar si hay relaciones fuertes con el salario.\n",
    "\n",
    "• Análisis de la cardinalidad de las variables categóricas → Ver cuántos valores únicos hay en cada una (ejemplo: ¿cuántos títulos de trabajo diferentes existen?).\n",
    "\n",
    "• Detección de valores atípicos (outliers) → Salarios extremadamente altos o bajos podrían distorsionar el modelo.\n",
    "\n",
    "• Manejo de valores nulos → Determinar si hay datos faltantes y cómo tratarlos.\n",
    "\n",
    "* 2️ Aplicación de un modelo no supervisado: PCA\n",
    "\n",
    "  \n",
    "Antes de entrenar un modelo de regresión, queremos reducir la dimensionalidad con PCA para:\n",
    "\n",
    "• Identificar patrones ocultos en los datos numéricos.\n",
    "\n",
    "• Reducir la redundancia si hay variables muy correlacionadas.\n",
    "\n",
    "• Visualice los datos en un espacio de menor dimensión y ver si se pueden agrupar según ciertas características.\n",
    "\n",
    "El PCA solo se aplicará a variables numéricas, así que las categóricas aún no se transforman en esta etapa.\n",
    "\n",
    "* 3️ Preparación de los datos para el modelo supervisado\n",
    "\n",
    "  \n",
    "Aquí ya nos preparamos para la regresión:\n",
    "a) Creación del Pipeline de preprocesamiento\n",
    "\n",
    "Dentro del Pipeline aplicaremos:\n",
    "\n",
    "• OneHotEncoding a variables categóricas: Convertimos texto en variables numéricas.\n",
    "\n",
    "• Estandarización o normalización de variables numéricas: PCA y modelos de regresión funcionan mejor con datos escalados.\n",
    "\n",
    "• Manejo de valores desconocidos en prueba : Configuramos OneHotEncoder(handle_unknown='ignore')para evitar errores si aparecen categorías nuevas en prueba.\n",
    "\n",
    "b) División Tren/Test\n",
    "\n",
    "Dividimos los datos en entrenamiento y prueba para evaluar el rendimiento del modelo.\n",
    "\n",
    "* 4️ Entrenamiento de modelos supervisados\n",
    "  \n",
    "• Probamos diferentes modelos de regresión:\n",
    "\n",
    "o Regresión Lineal (modelo base para interpretar resultados).\n",
    "\n",
    "o Random Forest Regresor (captura relaciones no lineales).\n",
    "\n",
    "o XGBoost o LightGBM (modelos más avanzados y eficientes).\n",
    "\n",
    "* 5 Evaluación del modelo\n",
    "  \n",
    "• Clave métrica: Usaremos MSE (Error Cuadrático Medio) y R² para medir la precisión del modelo.\n",
    "\n",
    "• Validación cruzada: Para evaluar el rendimiento real y evitar el sobreajuste.\n",
    "\n",
    "• GridSearchCV : Para optimizar hiperparámetros y encontrar la mejor configuración del modelo.\n",
    "\n",
    "\n",
    "### Orden en el que haremos cada paso\n",
    "\n",
    "Exploración de los datos (distribuciones, correlaciones, cardinalidad, valores atípicos, etc.)MIERCOLES\n",
    "\n",
    "Aplicación de PCA (solo a variables numéricas, para análisis exploratorio). JUEVES\n",
    "\n",
    "Creación del Pipeline de preprocesamiento (OneHotEncoding, escalado, etc.).VIERNES CLASE MAS DUDAS\n",
    "\n",
    "División Train/Test . FIND\n",
    "\n",
    "Entrenamiento de modelos supervisados. FINDE\n",
    "\n",
    "Evaluación del modelo con validación cruzada y GridSearchCV . FINDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd9306-3058-4449-b0b6-f27cdf4180ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
